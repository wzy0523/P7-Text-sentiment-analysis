{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19dd4d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b9d31-2523-4ebf-b731-887222431d23",
   "metadata": {},
   "source": [
    "# 1.Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582e5594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All:10000data\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('imdb_preprocess.csv',header=0)\n",
    "print('All:{}data'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60272a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori_text</th>\n",
       "      <th>sw_include</th>\n",
       "      <th>sw_exclude</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>i really like this summerslam due to the look ...</td>\n",
       "      <td>really like summerslam due look arena curtain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>not many television show appeal to quite a man...</td>\n",
       "      <td>many television show appeal quite many differe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>the film quickly get to a major chase scene wi...</td>\n",
       "      <td>film quickly get major chase scene ever increa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>jane austen would definitely approve of this o...</td>\n",
       "      <td>jane austen would definitely approve one gwyne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>expectation be somewhat high for me when i go ...</td>\n",
       "      <td>expectation somewhat high go see movie think s...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ori_text  \\\n",
       "0  I really liked this Summerslam due to the look...   \n",
       "1  Not many television shows appeal to quite as m...   \n",
       "2  The film quickly gets to a major chase scene w...   \n",
       "3  Jane Austen would definitely approve of this o...   \n",
       "4  Expectations were somewhat high for me when I ...   \n",
       "\n",
       "                                          sw_include  \\\n",
       "0  i really like this summerslam due to the look ...   \n",
       "1  not many television show appeal to quite a man...   \n",
       "2  the film quickly get to a major chase scene wi...   \n",
       "3  jane austen would definitely approve of this o...   \n",
       "4  expectation be somewhat high for me when i go ...   \n",
       "\n",
       "                                          sw_exclude  sentiment  \n",
       "0  really like summerslam due look arena curtain ...          1  \n",
       "1  many television show appeal quite many differe...          1  \n",
       "2  film quickly get major chase scene ever increa...         -1  \n",
       "3  jane austen would definitely approve one gwyne...          1  \n",
       "4  expectation somewhat high go see movie think s...         -1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9801f1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ori_text', 'sw_include', 'sw_exclude', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52c2ee-2936-4717-877c-dd8d410ffd6e",
   "metadata": {},
   "source": [
    "# 2.Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0baa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df['ori_text'])\n",
    "labels = list(df['sentiment'])\n",
    "type(labels)\n",
    "l = []\n",
    "num_classes = len(set(labels))\n",
    "if num_classes == 2: #II:+1\\-1\n",
    "    for i in labels:\n",
    "        if i == -1:\n",
    "            l.append(0)\n",
    "        if i  == 1:\n",
    "            l.append(1)\n",
    "    \n",
    "if num_classes == 3:\n",
    "    for i in labels:\n",
    "        if i == -1:\n",
    "            l.append(2)\n",
    "        if i == 0:\n",
    "            l.append(0)\n",
    "        if i == 1:\n",
    "            l.append(1)\n",
    "       \n",
    "labels = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328dcb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = ' <PAD>'  # Fill in sentences of different lengths\n",
    "pad_size =  64     # Fill as the same length\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sen2list = str(sentences[i]).split()\n",
    "    sentence_len = len(sen2list)\n",
    "    if sentence_len<pad_size:\n",
    "        sentences[i] += PAD*(pad_size-sentence_len)\n",
    "    else:\n",
    "        sentences[i] = \" \".join(sen2list[:pad_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a210cd0-3995-4953-b054-5cf709ee53a1",
   "metadata": {},
   "source": [
    "# 3.TextCnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2d88846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextCNN Parameter\n",
    "num_classes = len(set(labels))  # num_classes=2\n",
    "batch_size = 64\n",
    "word_list = \" \".join(sentences).split()\n",
    "vocab = list(set(word_list))\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d29b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(sentences, labels):\n",
    "    inputs = []\n",
    "    for sen in sentences:\n",
    "        inputs.append([word2idx[n] for n in sen.split()])\n",
    "\n",
    "    targets = []\n",
    "    for out in labels:\n",
    "        targets.append(out) # To using Torch Softmax Loss function\n",
    "    return inputs, targets\n",
    "input_batch, target_batch = make_data(sentences, labels)\n",
    "input_x = np.array(input_batch)\n",
    "target =  np.array(target_batch)\n",
    "input_batch, target_batch = torch.LongTensor(input_batch), torch.LongTensor(target_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fa176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Split the train and test sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(input_x,target,test_size=0.2,random_state = 0)\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.LongTensor(x_train), torch.LongTensor(y_train))\n",
    "test_dataset = Data.TensorDataset(torch.LongTensor(x_test), torch.LongTensor(y_test))\n",
    "dataset = Data.TensorDataset(input_batch, target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd576472",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,      # Data, encapsulated in the data.tensorDataset()\n",
    "    batch_size=batch_size,      # size\n",
    "    shuffle=True,               \n",
    "    num_workers=2,              # multiprocess\n",
    ")\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset,      \n",
    "    batch_size=batch_size,      \n",
    "    shuffle=True,               \n",
    "    num_workers=2, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635bdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.filter_sizes = (2, 3, 4)\n",
    "        self.embed = 300\n",
    "        self.num_filters = 256\n",
    "        self.dropout = 0.5\n",
    "        self.num_classes = num_classes\n",
    "        self.n_vocab = vocab_size\n",
    "        #The  character is padded to 0 by padding_idx</pad>\n",
    "        self.embedding = nn.Embedding(self.n_vocab, self.embed, padding_idx=word2idx['<PAD>'])\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, self.num_filters, (k, self.embed)) for k in self.filter_sizes])\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.fc = nn.Linear(self.num_filters * len(self.filter_sizes), self.num_classes)\n",
    "        \n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = out.unsqueeze(1)\n",
    "        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd0c1d-508b-4f02-8703-17691d753ba9",
   "metadata": {},
   "source": [
    "# 4. build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8663fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training\n",
    "for epoch in range(1):\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        pred = model(batch_x)\n",
    "        loss = criterion(pred, batch_y)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cd77176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1362/2000 (68%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc_list = []\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "\n",
    "        pred = output.max(1, keepdim=True)[1]                           \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "# test_loss /= len(test_loader.dataset)\n",
    "# test_loss_list.append(test_loss)\n",
    "test_acc_list.append(100. * correct / len(test_loader.dataset))\n",
    "print('Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d5f05d-ec48-4f5f-a449-07357d72b5a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Macintosh HD/users/Dell6/Desktop/1/model_1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMacintosh HD/users/Dell6/Desktop/1/model_1.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Macintosh HD/users/Dell6/Desktop/1/model_1.pt'"
     ]
    }
   ],
   "source": [
    "torch.save(model,'Macintosh HD/users/Dell6/Desktop/1/model_1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa0098-4057-4253-a692-cc0dc482da0c",
   "metadata": {},
   "source": [
    "# 5. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cfc5347-e7b3-4f92-82f4-3d9d7a76189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86863467-2fe8-4bcc-8ed9-6df8d5ec6390",
   "metadata": {},
   "source": [
    "# 6.Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdad87ef-2938-4a7b-86c7-4fb812fa5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load(PATH)\n",
    "#model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
